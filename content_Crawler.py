import os
import json
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# âœ… 1. JSON íŒŒì¼ ê²½ë¡œ ì§€ì •
json_path = "gknu_results.json"

# âœ… 2. ìƒˆë¡œìš´ í´ë” ì´ë¦„ ìƒì„± í•¨ìˆ˜
def generate_unique_folder(base_name="contents"):
    if not os.path.exists(base_name):
        return base_name
    i = 1
    while True:
        new_name = f"{base_name}_{i:02d}"
        if not os.path.exists(new_name):
            return new_name
        i += 1

# âœ… 3. í´ë” ìƒì„±
base_folder = generate_unique_folder("contents")
os.makedirs(base_folder, exist_ok=True)

contents_dir = os.path.join(base_folder, "contents")
download_dir = os.path.join(base_folder, "download")
os.makedirs(contents_dir, exist_ok=True)
os.makedirs(download_dir, exist_ok=True)

# âœ… 4. JSON ë¡œë“œ
with open(json_path, "r", encoding="utf-8") as f:
    data = json.load(f)

base_url = "https://www.gknu.ac.kr"

# âœ… 5. í•­ëª©ë³„ ì²˜ë¦¬
for idx, item in enumerate(data, start=1):
    title = item["title"]
    url = item["url"]
    print(f"\nğŸ” [{idx}] ì²˜ë¦¬ ì¤‘: {title}")

    try:
        response = requests.get(url)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, "html.parser")

        # âœ… ë³¸ë¬¸ ì¶”ì¶œ ë° ì €ì¥
        content_div = soup.select_one("div.board-view-cont")
        if content_div:
            spans = content_div.select("p span")
            full_text = "\n".join(span.get_text(strip=True) for span in spans if span.get_text(strip=True))

            text_file = os.path.join(contents_dir, f"{idx:02d}_content.txt")
            with open(text_file, "w", encoding="utf-8") as f:
                f.write(full_text)
            print(f"ğŸ“ ë³¸ë¬¸ ì €ì¥ ì™„ë£Œ: {text_file}")
        else:
            print("âŒ ë³¸ë¬¸ ì½˜í…ì¸  ì—†ìŒ")

        # âœ… ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        clip_div = soup.select_one("div.clip")
        if clip_div:
            for a_tag in clip_div.find_all("a", href=True):
                file_url = urljoin(base_url, a_tag["href"])
                file_name = a_tag.get_text(strip=True).split("(")[0]

                try:
                    file_data = requests.get(file_url)
                    file_path = os.path.join(download_dir, file_name)
                    with open(file_path, "wb") as f:
                        f.write(file_data.content)
                    print(f"âœ… ì²¨ë¶€íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")
                except Exception as e:
                    print(f"âŒ ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {file_url} / ì´ìœ : {e}")
        else:
            print("ğŸ“‚ ì²¨ë¶€íŒŒì¼ ì—†ìŒ")
    except Exception as e:
        print(f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {url} / ì´ìœ : {e}")
